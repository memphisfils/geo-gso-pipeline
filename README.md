# ğŸš€ GEO/GSO Pipeline â€” Article Generation & Scoring

Pipeline CLI Python qui gÃ©nÃ¨re automatiquement des articles **GEO-ready** (optimisÃ©s pour les moteurs de recherche gÃ©nÃ©ratifs type ChatGPT, Gemini, Perplexity), avec scoring qualitÃ©, anti-duplication et export publication-ready.

## ğŸ“¦ Installation

```bash
# Cloner le repo
git clone <repo-url>
cd geo-gso-pipeline

# CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # macOS/Linux

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configurer les secrets
cp .env.example .env
# Ã‰diter .env et ajouter votre clÃ© OPENAI_API_KEY
```

## â–¶ï¸ ExÃ©cution

```bash
# Lancement standard
python generate.py --input topics.json --output ./out

# Avec traitement parallÃ¨le (bonus)
python generate.py --input topics.json --output ./out --parallel
```

### Output

Le dossier `./out` contiendra :

```
out/
â”œâ”€â”€ articles/    # 1 fichier .md par article (Markdown)
â”œâ”€â”€ json/        # 1 fichier .json par article (publication-ready)
â”œâ”€â”€ html/        # 1 fichier .html par article (avec SEO meta tags)
â””â”€â”€ summary.json # Rapport global (scores, duplicates, erreurs)
```

## ğŸ—ï¸ Architecture

```
geo-gso-pipeline/
â”œâ”€â”€ generate.py              # CLI entrypoint (orchestration)
â”œâ”€â”€ topics.json              # Input : 10 sujets (fr/en)
â”œâ”€â”€ requirements.txt         # DÃ©pendances Python
â”œâ”€â”€ .env.example             # Template des variables d'environnement
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py            # Configuration & chargement .env
â”‚   â”œâ”€â”€ llm_client.py        # Client OpenAI + retries/backoff
â”‚   â”œâ”€â”€ article_generator.py # GÃ©nÃ©ration structurÃ©e GEO + validation
â”‚   â”œâ”€â”€ scorer.py            # Scoring qualitÃ© (5 critÃ¨res, /100)
â”‚   â”œâ”€â”€ deduplication.py     # Anti-duplication par embeddings
â”‚   â””â”€â”€ exporter.py          # Export MD/JSON/HTML + summary
â””â”€â”€ out/                     # Output gÃ©nÃ©rÃ©
```

## ğŸ”§ Choix Techniques

### LLM : OpenAI GPT-4o
- **Pourquoi** : Meilleur rapport qualitÃ©/coÃ»t pour la gÃ©nÃ©ration d'articles structurÃ©s longs
- **Retries** : Backoff exponentiel (2s/4s/8s) sur `RateLimitError`, `APITimeoutError`, `APIConnectionError`
- **Prompt engineering** : Prompt systÃ¨me + utilisateur en 2 Ã©tapes avec format obligatoire strict

### Scoring : 5 critÃ¨res (/20 chacun â†’ total /100)

| CritÃ¨re | Ce qui est mesurÃ© |
|---------|-------------------|
| **Structure** | PrÃ©sence des 8 sections obligatoires (H1, meta, intro, TOC, corps, FAQ, takeaways, sources, auteur) |
| **LisibilitÃ©** | Score Flesch via `textstat` + analyse des listes et du formatage |
| **Sources** | Nombre â‰¥ 3 + diversitÃ© des domaines |
| **LLM-friendliness** | RÃ©ponses directes, listes, FAQ, densitÃ© d'info, entitÃ©s |
| **Risque duplication** | Score de similaritÃ© cosinus max avec les autres articles |

### Anti-duplication : Embeddings + Cosine Similarity
- **ModÃ¨le** : `sentence-transformers/all-MiniLM-L6-v2` (exÃ©cution locale, pas d'appel API)
- **MÃ©thode** : Cosine similarity via `sklearn.metrics.pairwise`
- **Seuil** : Configurable (dÃ©faut: 0.85). Au-delÃ  â†’ rejet avec warning
- **Avantage** : DÃ©tection sÃ©mantique (pas juste lexicale), rÃ©sistant Ã  la paraphrase

### Export
- **Markdown** : Article complet prÃªt Ã  publier
- **JSON** : SchÃ©ma structurÃ© avec slug, meta, FAQ, scores, auteur
- **HTML (bonus)** : Page autonome avec `og:title`, `og:description`, Twitter Cards, CSS intÃ©grÃ©

## âš ï¸ Limites & AmÃ©liorations ProposÃ©es

### Limites actuelles
- **Sources** : Les URLs gÃ©nÃ©rÃ©es par le LLM sont plausibles mais pas vÃ©rifiÃ©es. Un module de fact-checking serait nÃ©cessaire en production
- **Volume** : Le pipeline sÃ©quentiel est limitÃ© par le rate limit de l'API OpenAI (~10 articles/run)
- **Validation** : La dÃ©tection des sections est basÃ©e sur des regex, ce qui peut Ãªtre fragile face Ã  des formats markdown inhabituels

### AmÃ©liorations pour le scaling
- **Queue / Workers** : IntÃ©grer Celery ou Redis Queue pour le batch processing asynchrone
- **CMS Integration** : Publication automatique via WordPress REST API ou headless CMS (Strapi, Contentful)
- **Monitoring** : Dashboard Grafana pour suivre les scores, le coÃ»t API, le throughput
- **RAG** : Module Retrieval-Augmented Generation pour citer des sources rÃ©elles depuis une base documentaire
- **Source Verification** : Scraping + vÃ©rification des URLs de sources gÃ©nÃ©rÃ©es
- **Multi-LLM** : Fallback automatique entre OpenAI â†’ Anthropic â†’ Mistral
- **Cache** : Mise en cache des embeddings pour accÃ©lÃ©rer la dÃ©duplication sur les runs successifs

## ğŸ“„ Variables d'Environnement

| Variable | Description | DÃ©faut |
|----------|-------------|--------|
| `OPENAI_API_KEY` | ClÃ© API OpenAI (obligatoire) | â€” |
| `LLM_MODEL` | ModÃ¨le LLM Ã  utiliser | `gpt-4o` |
| `SIMILARITY_THRESHOLD` | Seuil de similaritÃ© pour la dÃ©duplication | `0.85` |
| `MAX_RETRIES` | Nombre max de retries API | `3` |
| `REQUEST_TIMEOUT` | Timeout API en secondes | `90` |

## ğŸ“‹ Licence

MIT
